## HTTP/2：如何提升网络速度？

http/1.1 
1. 增加了持久化链接
2. 浏览器为每个域名同时维护6个TCP 持久链接
3. 使用CDN 实现域名分片机制

大大提高了页面下载速度

对带宽的利用率却并不理想，HTTP/1.1 的一个核心问题

带宽是指每秒最大能发送或者接收的字节数。 上行带宽，每秒能够接收的最大字节数称为下行带宽。

是因为 HTTP/1.1 很难将带宽用满。比如我们常说的 100M 带宽，实际的下载速度能达到 12.5M/S，而采用 HTTP/1.1 时，也许在加载页面资源时最大只能使用到 2.5M/S，很难将 12.5M 全部用满。

- 第一个原因，TCP 的慢启动。
会有从 0 到一个稳定速度的提速过程，TCP 的慢启动就类似于该过程。
首次渲染页面的时长
慢启动是 TCP 为了减少网络拥塞的一种策略，我们是没有办法改变的。

- 第二个原因，同时开启了多条 TCP 连接，那么这些连接会竞争固定的带宽。
使用了 3 个 CDN，那么加载该网页的时候就需要建立 6 * 3，也就是 18 个 TCP 连接来下载资源；在下载过程中，当发现带宽不足的时候，各个 TCP 连接就需要动态减慢接收数据的速度。这样就会出现一个问题，因为有的 TCP 连接下载的是一些关键资源，如 CSS 文件、JavaScript 文件等，而有的 TCP 连接下载的是图片、视频等普通的资源文件，但是多条 TCP 连接之间又不能协商让哪些关键资源优先下载，这样就有可能影响那些关键资源的下载速度了。
第三个原因，HTTP/1.1 队头阻塞的问题。
我们知道在 HTTP/1.1 中使用持久连接时，虽然能公用一个 TCP 管道，但是在一个管道中同一时刻只能处理一个请求，在当前的请求没有结束之前，其他的请求只能处于阻塞状态。这意味着我们不能随意在一个管道中发送请求和接收内容。


## HTTP/2 的多路复用
TCP 的慢启动和 TCP 连接之间的竞争问题。
一个域名只使用一个 TCP 长连接和消除队头阻塞问题。
服务器端接收到这些请求后，会根据自己的喜好来决定优先返回哪些内容，比如服务器可能早就缓存好了 index.html 和 bar.js 的响应头信息，那么当接收到请求的时候就可以立即把 index.html 和 bar.js 的响应头信息返回给浏览器，然后再将 index.html 和 bar.js 的响应体数据返回给浏览器。
之所以可以随意发送，是因为每份数据都有对应的 ID，浏览器接收到之后，会筛选出相同 ID 的内容，将其拼接为完整的 HTTP 响应数据。

使用 HTTP/2 能带来 20%～60% 的效率提升，至于 20% 还是 60% 要看优化的程度
头部压缩
  这里的头部指的是http请求头headers。大家可能会想请求头能有多大呢，跟资源相比算不上啥。其实不然，随着互联网的发展，请求头里携带的数据越来越多了，随随便一个“user-agent”就一长串。另外cookie也会被存放越来越多的信息。更烦的是，一个页面所有的请求，都会带上这些重复的请求头数据。
  HPACK算法
多路复用 
  虽然http1.x里有keep-alive可以避免TCP三次握手，但是keep-alive又是串行的。所以要么并行多握手，要么串行不握手，都不是最好的结果，我们希望的是并行也不握手。
优先级和依赖性
服务器推送